{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_ids =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ In IR hit rate, input query will be set to __record__.app.retrieve_and_generate.args.query .\n",
      "✅ In IR hit rate, input retrieved_context_chunks will be set to __record__.app.retrieve_and_generate.rets[1] .\n",
      "✅ In IR hit rate, input k will be set to __record__.app.retrieve_and_generate.args.k .\n",
      "✅ In NDCG@k, input query will be set to __record__.app.retrieve_and_generate.args.query .\n",
      "✅ In NDCG@k, input retrieved_context_chunks will be set to __record__.app.retrieve_and_generate.rets[1] .\n",
      "✅ In NDCG@k, input relevance_scores will be set to __record__.app.retrieve_and_generate.rets[2] .\n",
      "✅ In NDCG@k, input k will be set to __record__.app.retrieve_and_generate.args.k .\n",
      "✅ In Recall@k, input query will be set to __record__.app.retrieve_and_generate.args.query .\n",
      "✅ In Recall@k, input retrieved_context_chunks will be set to __record__.app.retrieve_and_generate.rets[1] .\n",
      "✅ In Recall@k, input relevance_scores will be set to __record__.app.retrieve_and_generate.rets[2] .\n",
      "✅ In Recall@k, input k will be set to __record__.app.retrieve_and_generate.args.k .\n",
      "✅ In Ground Truth answer (semantic similarity), input prompt will be set to __record__.app.retrieve_and_generate.args.query .\n",
      "✅ In Ground Truth answer (semantic similarity), input response will be set to __record__.app.retrieve_and_generate.rets[0] .\n"
     ]
    }
   ],
   "source": [
    "from cohere_ret.cohere_ret import cohere_retriever\n",
    "from cohere_ret.generator import cohere_generator\n",
    "from gemini.retrieve import gemini_retriever\n",
    "from openai_class.retriever import openai_retriever\n",
    "from openai_class.generator import openai_generator\n",
    "from voyageai_ret.retrieve import voyage_retriever\n",
    "from gemini.generator import gemini_generator\n",
    "from utils.prepare_ground_truth import LatestGroundTruthCSV\n",
    "from evaluator.ret_eval import rag_app, retriever_evaluator\n",
    "from utils.chunk_scorer import score_chunk\n",
    "import json\n",
    "\n",
    "\n",
    "\n",
    "with open(r'data\\data_1000_v3.0.json', 'r') as f:\n",
    "   ground_truth = json.loads(f.read())\n",
    "\n",
    "\n",
    "ret = gemini_retriever()\n",
    "gen = openai_generator()\n",
    "rag_app = rag_app(ret, gen,ground_truth[\"expected_response\"],ground_truth[\"query\"])\n",
    "\n",
    "#eval-{Retriever}-{generator}-{chunksize}\n",
    "ret_eval = retriever_evaluator(name=\"eval_gemini_openai_1000_@5\",ground_truth=ground_truth,rag_app=rag_app, reset_db=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved and evaluated 4.3478260869565215% \"How do I register for controlled or semi-controlled drugs custody?\"\n",
      "retrieved and evaluated 8.695652173913043% \"What are the requirements for renewing the registration of a conventional pharmaceutical product?\"\n",
      "retrieved and evaluated 13.043478260869565% \"How do I appeal a decision made by the Medical Licensing Committee?\"\n",
      "retrieved and evaluated 17.391304347826086% \"What is the process for obtaining a certificate of amendment for registered pharmaceutical products?\"\n",
      "retrieved and evaluated 21.73913043478261% \"How can I get a product classified?\"\n",
      "retrieved and evaluated 26.08695652173913% \"What are the steps to re-license a pharmaceutical facility?\"\n",
      "retrieved and evaluated 30.434782608695652% \"How can I renew my license as a nurse or medical professional?\"\n",
      "retrieved and evaluated 34.78260869565217% \"What's the process for getting a permit to import medical equipment?\"\n",
      "retrieved and evaluated 39.130434782608695% \"How can I renew my health facility license?\"\n",
      "retrieved and evaluated 43.47826086956522% \"What are the steps to register a change in a doctor's professional title?\"\n",
      "retrieved and evaluated 47.82608695652174% \"How do I re-license a health facility after cancellation or suspension?\"\n",
      "retrieved and evaluated 52.17391304347826% \"How do I change the technical director of my private medical facility?\"\n",
      "retrieved and evaluated 56.52173913043478% \"What's the process for re-licensing nurses and medical professionals?\"\n",
      "retrieved and evaluated 60.869565217391305% \"How can I request a list of licensed pharmaceutical facilities in the UAE?\"\n",
      "retrieved and evaluated 65.21739130434783% \"How do I renew my registration certificate to practice nursing or midwifery?\"\n",
      "retrieved and evaluated 69.56521739130434% \"What are the requirement documents for the good standing certificate of medical staff in the sector the is fee-exempt for renewal staff licenses?\"\n",
      "retrieved and evaluated 73.91304347826087% \" I have a medical equipment that is manufactured from animal-based products, What is the condition to renew the license? \"\n",
      "retrieved and evaluated 78.26086956521739% \"What are the fees to renew the document I get to open a clinic in the UAE? \"\n",
      "retrieved and evaluated 82.6086956521739% \"What are the required documents to apply for the approval of the service that enables employees to apply and approve their applications but for private entity employees? \"\n",
      "retrieved and evaluated 86.95652173913044% \"Do healthcare facilities need to fulfill specific requirements regarding elevator installations and what medical staff arrangements are required for operations?\"\n",
      "retrieved and evaluated 91.30434782608695% \"Can pharmaceutical companies export narcotic drugs and what are the validity requirements for such permits?\"\n",
      "retrieved and evaluated 95.65217391304348% \"Are there specific requirements for medical professionals over 60 years old and what documentation is needed for their continued practice?\"\n",
      "retrieved and evaluated 100.0% \"What restrictions apply to medical advertising on websites and social media, and how does the licensing differ between platforms?\"\n"
     ]
    }
   ],
   "source": [
    "ret_eval.run(k=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_ids.append(ret_eval.tru_app.app_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Ground Truth answer (semantic similarity)</th>\n",
       "      <th>IR hit rate</th>\n",
       "      <th>NDCG@k</th>\n",
       "      <th>Recall@k</th>\n",
       "      <th>latency</th>\n",
       "      <th>total_cost</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>app_name</th>\n",
       "      <th>app_version</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>eval_cohere_openai_1000_@5</th>\n",
       "      <th>base</th>\n",
       "      <td>0.786957</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.097566</td>\n",
       "      <td>7.175094</td>\n",
       "      <td>0.000337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_gemini_openai_1000_@5</th>\n",
       "      <th>base</th>\n",
       "      <td>0.754545</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.118280</td>\n",
       "      <td>7.051819</td>\n",
       "      <td>0.000327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_openai_openai_1000_@5</th>\n",
       "      <th>base</th>\n",
       "      <td>0.743478</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.131128</td>\n",
       "      <td>9.268177</td>\n",
       "      <td>0.000339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_gemini_openai_1000_@3</th>\n",
       "      <th>base</th>\n",
       "      <td>0.734783</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.096541</td>\n",
       "      <td>6.092229</td>\n",
       "      <td>0.000247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_openai_openai_1000_@3</th>\n",
       "      <th>base</th>\n",
       "      <td>0.734783</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.081738</td>\n",
       "      <td>7.438992</td>\n",
       "      <td>0.000280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_cohere_openai_1000_@3</th>\n",
       "      <th>base</th>\n",
       "      <td>0.691304</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.058746</td>\n",
       "      <td>7.388845</td>\n",
       "      <td>0.000261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_voyage_openai_1000_@5</th>\n",
       "      <th>base</th>\n",
       "      <td>0.634783</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.117465</td>\n",
       "      <td>6.105467</td>\n",
       "      <td>0.000273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_voyage_openai_1000_@3</th>\n",
       "      <th>base</th>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.066717</td>\n",
       "      <td>5.822982</td>\n",
       "      <td>0.000223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Ground Truth answer (semantic similarity)  \\\n",
       "app_name                   app_version                                              \n",
       "eval_cohere_openai_1000_@5 base                                          0.786957   \n",
       "eval_gemini_openai_1000_@5 base                                          0.754545   \n",
       "eval_openai_openai_1000_@5 base                                          0.743478   \n",
       "eval_gemini_openai_1000_@3 base                                          0.734783   \n",
       "eval_openai_openai_1000_@3 base                                          0.734783   \n",
       "eval_cohere_openai_1000_@3 base                                          0.691304   \n",
       "eval_voyage_openai_1000_@5 base                                          0.634783   \n",
       "eval_voyage_openai_1000_@3 base                                          0.565217   \n",
       "\n",
       "                                        IR hit rate  NDCG@k  Recall@k  \\\n",
       "app_name                   app_version                                  \n",
       "eval_cohere_openai_1000_@5 base            0.347826     1.0  0.097566   \n",
       "eval_gemini_openai_1000_@5 base            0.434783     1.0  0.118280   \n",
       "eval_openai_openai_1000_@5 base            0.478261     1.0  0.131128   \n",
       "eval_gemini_openai_1000_@3 base            0.391304     1.0  0.096541   \n",
       "eval_openai_openai_1000_@3 base            0.347826     1.0  0.081738   \n",
       "eval_cohere_openai_1000_@3 base            0.217391     1.0  0.058746   \n",
       "eval_voyage_openai_1000_@5 base            0.521739     1.0  0.117465   \n",
       "eval_voyage_openai_1000_@3 base            0.260870     1.0  0.066717   \n",
       "\n",
       "                                         latency  total_cost  \n",
       "app_name                   app_version                        \n",
       "eval_cohere_openai_1000_@5 base         7.175094    0.000337  \n",
       "eval_gemini_openai_1000_@5 base         7.051819    0.000327  \n",
       "eval_openai_openai_1000_@5 base         9.268177    0.000339  \n",
       "eval_gemini_openai_1000_@3 base         6.092229    0.000247  \n",
       "eval_openai_openai_1000_@3 base         7.438992    0.000280  \n",
       "eval_cohere_openai_1000_@3 base         7.388845    0.000261  \n",
       "eval_voyage_openai_1000_@5 base         6.105467    0.000273  \n",
       "eval_voyage_openai_1000_@3 base         5.822982    0.000223  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret_eval.session.get_leaderboard(app_ids=app_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'app_hash_105cc663f8f87c806edbed23e90495f4'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret_eval.tru_app.app_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
